['project2.py', 'data/small/CS205_small_testdata__10.txt', '0']
The data has 10 features in total.
in 1th round
select feature 1, with accuracy 0.6966666666666667
select feature 2, with accuracy 0.8133333333333334
select feature 3, with accuracy 0.6733333333333333
select feature 4, with accuracy 0.6866666666666666
select feature 5, with accuracy 0.6666666666666666
select feature 6, with accuracy 0.6866666666666666
select feature 7, with accuracy 0.6933333333333334
select feature 8, with accuracy 0.67
select feature 9, with accuracy 0.6466666666666666
select feature 10, with accuracy 0.66
feature set [2] was best, with accuracy 0.8133333333333334
in 2th round
select feature 1, with accuracy 0.8433333333333334
select feature 3, with accuracy 0.81
select feature 4, with accuracy 0.8533333333333334
select feature 5, with accuracy 0.79
select feature 6, with accuracy 0.87
select feature 7, with accuracy 0.8466666666666667
select feature 8, with accuracy 0.8533333333333334
select feature 9, with accuracy 0.9633333333333334
select feature 10, with accuracy 0.8566666666666667
feature set [2, 9] was best, with accuracy 0.9633333333333334
in 3th round
select feature 1, with accuracy 0.8933333333333333
select feature 3, with accuracy 0.93
select feature 4, with accuracy 0.92
select feature 5, with accuracy 0.8966666666666666
select feature 6, with accuracy 0.87
select feature 7, with accuracy 0.9133333333333333
select feature 8, with accuracy 0.92
select feature 10, with accuracy 0.9266666666666666
feature set [2, 9, 3] was best, with accuracy 0.93
in 4th round
select feature 1, with accuracy 0.8466666666666667
select feature 4, with accuracy 0.8233333333333334
select feature 5, with accuracy 0.84
select feature 6, with accuracy 0.8733333333333333
select feature 7, with accuracy 0.9066666666666666
select feature 8, with accuracy 0.88
select feature 10, with accuracy 0.87
feature set [2, 9, 3, 7] was best, with accuracy 0.9066666666666666
in 5th round
select feature 1, with accuracy 0.8
select feature 4, with accuracy 0.83
select feature 5, with accuracy 0.8333333333333334
select feature 6, with accuracy 0.8466666666666667
select feature 8, with accuracy 0.8566666666666667
select feature 10, with accuracy 0.86
feature set [2, 9, 3, 7, 10] was best, with accuracy 0.86
in 6th round
select feature 1, with accuracy 0.7833333333333333
select feature 4, with accuracy 0.8
select feature 5, with accuracy 0.79
select feature 6, with accuracy 0.83
select feature 8, with accuracy 0.8166666666666667
feature set [2, 9, 3, 7, 10, 6] was best, with accuracy 0.83
in 7th round
select feature 1, with accuracy 0.7766666666666666
select feature 4, with accuracy 0.7766666666666666
select feature 5, with accuracy 0.8
select feature 8, with accuracy 0.8066666666666666
feature set [2, 9, 3, 7, 10, 6, 8] was best, with accuracy 0.8066666666666666
in 8th round
select feature 1, with accuracy 0.79
select feature 4, with accuracy 0.76
select feature 5, with accuracy 0.76
feature set [2, 9, 3, 7, 10, 6, 8, 1] was best, with accuracy 0.79
in 9th round
select feature 4, with accuracy 0.7366666666666667
select feature 5, with accuracy 0.7466666666666667
feature set [2, 9, 3, 7, 10, 6, 8, 1, 5] was best, with accuracy 0.7466666666666667
in 10th round
select feature 4, with accuracy 0.7266666666666667
feature set [2, 9, 3, 7, 10, 6, 8, 1, 5, 4] was best, with accuracy 0.7266666666666667
Finished search! The best feature set is [2, 9]. with accuracy 0.9633333333333334.
