['project2.py', 'data/small/CS205_small_testdata__23.txt', '0']
The data has 10 features in total.
in 1th round
select feature 1, with accuracy 0.85
select feature 2, with accuracy 0.73
select feature 3, with accuracy 0.7133333333333334
select feature 4, with accuracy 0.7333333333333333
select feature 5, with accuracy 0.7233333333333334
select feature 6, with accuracy 0.7
select feature 7, with accuracy 0.7366666666666667
select feature 8, with accuracy 0.7166666666666667
select feature 9, with accuracy 0.7233333333333334
select feature 10, with accuracy 0.7566666666666667
feature set [1] was best, with accuracy 0.85
in 2th round
select feature 2, with accuracy 0.95
select feature 3, with accuracy 0.8266666666666667
select feature 4, with accuracy 0.8166666666666667
select feature 5, with accuracy 0.8033333333333333
select feature 6, with accuracy 0.8033333333333333
select feature 7, with accuracy 0.81
select feature 8, with accuracy 0.8633333333333333
select feature 9, with accuracy 0.8366666666666667
select feature 10, with accuracy 0.8266666666666667
feature set [1, 2] was best, with accuracy 0.95
in 3th round
select feature 3, with accuracy 0.91
select feature 4, with accuracy 0.91
select feature 5, with accuracy 0.9266666666666666
select feature 6, with accuracy 0.8933333333333333
select feature 7, with accuracy 0.8933333333333333
select feature 8, with accuracy 0.9233333333333333
select feature 9, with accuracy 0.9
select feature 10, with accuracy 0.8733333333333333
feature set [1, 2, 5] was best, with accuracy 0.9266666666666666
in 4th round
select feature 3, with accuracy 0.8966666666666666
select feature 4, with accuracy 0.8633333333333333
select feature 6, with accuracy 0.87
select feature 7, with accuracy 0.8466666666666667
select feature 8, with accuracy 0.89
select feature 9, with accuracy 0.87
select feature 10, with accuracy 0.8333333333333334
feature set [1, 2, 5, 3] was best, with accuracy 0.8966666666666666
in 5th round
select feature 4, with accuracy 0.8133333333333334
select feature 6, with accuracy 0.8266666666666667
select feature 7, with accuracy 0.82
select feature 8, with accuracy 0.8333333333333334
select feature 9, with accuracy 0.84
select feature 10, with accuracy 0.8
feature set [1, 2, 5, 3, 9] was best, with accuracy 0.84
in 6th round
select feature 4, with accuracy 0.8
select feature 6, with accuracy 0.7866666666666666
select feature 7, with accuracy 0.7866666666666666
select feature 8, with accuracy 0.7933333333333333
select feature 10, with accuracy 0.8
feature set [1, 2, 5, 3, 9, 4] was best, with accuracy 0.8
in 7th round
select feature 6, with accuracy 0.7266666666666667
select feature 7, with accuracy 0.77
select feature 8, with accuracy 0.7733333333333333
select feature 10, with accuracy 0.76
feature set [1, 2, 5, 3, 9, 4, 8] was best, with accuracy 0.7733333333333333
in 8th round
select feature 6, with accuracy 0.7633333333333333
select feature 7, with accuracy 0.7433333333333333
select feature 10, with accuracy 0.7333333333333333
feature set [1, 2, 5, 3, 9, 4, 8, 6] was best, with accuracy 0.7633333333333333
in 9th round
select feature 7, with accuracy 0.7466666666666667
select feature 10, with accuracy 0.7433333333333333
feature set [1, 2, 5, 3, 9, 4, 8, 6, 7] was best, with accuracy 0.7466666666666667
in 10th round
select feature 10, with accuracy 0.7333333333333333
feature set [1, 2, 5, 3, 9, 4, 8, 6, 7, 10] was best, with accuracy 0.7333333333333333
Finished search! The best feature set is [1, 2]. with accuracy 0.95.
